{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 320 books to '../data/raw/books_raw_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_books(subject='fiction', max_results=40, start_index=0):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes\"\n",
    "    params = {\n",
    "        'q': f\"subject:{subject}\",\n",
    "        'maxResults': max_results,\n",
    "        'startIndex': start_index,\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    return data.get('items', [])\n",
    "\n",
    "def parse_book(item):\n",
    "    volume = item.get('volumeInfo', {})\n",
    "    \n",
    "    return {\n",
    "        'book_id': item.get('id'),\n",
    "        'title': volume.get('title'),\n",
    "        'authors': ', '.join(volume.get('authors', [])),\n",
    "        'publication_date': volume.get('publishedDate'),\n",
    "        'page_count': volume.get('pageCount'),\n",
    "        'genre_name': ', '.join(volume.get('categories', [])) if volume.get('categories') else 'Unknown',\n",
    "        'genre_id': None,  # will be filled later\n",
    "        'categories': ', '.join(volume.get('categories', [])) if volume.get('categories') else '',\n",
    "        'average_rating': volume.get('averageRating'),\n",
    "        'ratings_count': volume.get('ratingsCount'),\n",
    "        'description': volume.get('description'),\n",
    "        'language': volume.get('language'),\n",
    "        'publisher': volume.get('publisher'),\n",
    "        'isbn_13': None,\n",
    "        'isbn_10': None,\n",
    "        'thumbnail': volume.get('imageLinks', {}).get('thumbnail'),\n",
    "        'info_link': volume.get('infoLink'),\n",
    "        'collected_date': datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "def extract_isbns(industry_identifiers):\n",
    "    isbn_10, isbn_13 = None, None\n",
    "    for iden in industry_identifiers:\n",
    "        if iden['type'] == 'ISBN_10':\n",
    "            isbn_10 = iden['identifier']\n",
    "        elif iden['type'] == 'ISBN_13':\n",
    "            isbn_13 = iden['identifier']\n",
    "    return isbn_10, isbn_13\n",
    "\n",
    "def enrich_books_with_isbn(book_list, items):\n",
    "    for book, item in zip(book_list, items):\n",
    "        industry_ids = item.get('volumeInfo', {}).get('industryIdentifiers', [])\n",
    "        isbn_10, isbn_13 = extract_isbns(industry_ids)\n",
    "        book['isbn_10'] = isbn_10\n",
    "        book['isbn_13'] = isbn_13\n",
    "    return book_list\n",
    "\n",
    "# üß™ Example: Fetch 80 books from 'science' and 'fiction'\n",
    "subjects = ['science', 'fiction','romance','mystery']\n",
    "all_books = []\n",
    "\n",
    "for subject in subjects:\n",
    "    for start in range(0, 80, 40):  # Google Books API allows max 40 results per call\n",
    "        items = fetch_books(subject, max_results=40, start_index=start)\n",
    "        parsed_books = [parse_book(item) for item in items]\n",
    "        parsed_books = enrich_books_with_isbn(parsed_books, items)\n",
    "        all_books.extend(parsed_books)\n",
    "\n",
    "# üìÅ Convert to DataFrame and save\n",
    "df_books = pd.DataFrame(all_books)\n",
    "df_books.to_csv('../data/raw/books_raw_data.csv', index=False)\n",
    "print(f\"‚úÖ Saved {len(df_books)} books to '../data/raw/books_raw_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Starting book data collection for ME204 Final Project\n",
      "============================================================\n",
      "üìÅ Found existing data file: ../data/raw/books_raw_data.csv\n",
      "‚úÖ Successfully loaded 320 books from existing file\n",
      "\n",
      "üìä Data Analysis:\n",
      "   Total books: 320\n",
      "   Columns: ['book_id', 'title', 'authors', 'publication_date', 'page_count', 'genre_name', 'genre_id', 'categories', 'average_rating', 'ratings_count', 'description', 'language', 'publisher', 'isbn_13', 'isbn_10', 'thumbnail', 'info_link', 'collected_date']\n",
      "\n",
      "üìö Books by Genre:\n",
      "   Fiction: 164 books\n",
      "   Science: 31 books\n",
      "   Unknown: 28 books\n",
      "   Nature: 11 books\n",
      "   Detective and mystery stories: 7 books\n",
      "   Biography & Autobiography: 7 books\n",
      "   Technology & Engineering: 6 books\n",
      "   History: 5 books\n",
      "   Medical: 4 books\n",
      "   Juvenile Fiction: 4 books\n",
      "   Children's stories: 3 books\n",
      "   Books and reading: 3 books\n",
      "   England: 3 books\n",
      "   Computers: 2 books\n",
      "   Social Science: 2 books\n",
      "   Health & Fitness: 2 books\n",
      "   Philosophy: 2 books\n",
      "   Drama: 2 books\n",
      "   Romance: 2 books\n",
      "   Brunetti, Guido (Fictitious character): 1 books\n",
      "   Boarding school students: 1 books\n",
      "   Detective and mystery stories, English: 1 books\n",
      "   British: 1 books\n",
      "   Anonymous letters: 1 books\n",
      "   Classic literature: 1 books\n",
      "   Criminals: 1 books\n",
      "   Art: 1 books\n",
      "   Beresford, Tommy (Fictitious character): 1 books\n",
      "   Adventure stories: 1 books\n",
      "   Corruption: 1 books\n",
      "   English fiction: 1 books\n",
      "   Avarice: 1 books\n",
      "   Boarding schools: 1 books\n",
      "   Brothers and sisters: 1 books\n",
      "   Language Arts & Disciplines: 1 books\n",
      "   Ballads, English: 1 books\n",
      "   Blind: 1 books\n",
      "   Family secrets: 1 books\n",
      "   Black humor: 1 books\n",
      "   Political Science: 1 books\n",
      "   England, Northern: 1 books\n",
      "   Gordon Riots, 1780: 1 books\n",
      "   Fantasy: 1 books\n",
      "   Comics & Graphic Novels: 1 books\n",
      "   Mathematics: 1 books\n",
      "   Family & Relationships: 1 books\n",
      "   Pets: 1 books\n",
      "   Gardening: 1 books\n",
      "   Architecture: 1 books\n",
      "   Civilization: 1 books\n",
      "   Police: 1 books\n",
      "\n",
      "üîç Data Quality Check:\n",
      "   book_id: 320/320 (100.0%) non-null\n",
      "   title: 320/320 (100.0%) non-null\n",
      "   authors: 316/320 (98.8%) non-null\n",
      "   publication_date: 318/320 (99.4%) non-null\n",
      "   page_count: 316/320 (98.8%) non-null\n",
      "   genre_name: 320/320 (100.0%) non-null\n",
      "   genre_id: 0/320 (0.0%) non-null\n",
      "   categories: 292/320 (91.2%) non-null\n",
      "   average_rating: 59/320 (18.4%) non-null\n",
      "   ratings_count: 59/320 (18.4%) non-null\n",
      "   description: 305/320 (95.3%) non-null\n",
      "   language: 320/320 (100.0%) non-null\n",
      "   publisher: 256/320 (80.0%) non-null\n",
      "   isbn_13: 278/320 (86.9%) non-null\n",
      "   isbn_10: 264/320 (82.5%) non-null\n",
      "   thumbnail: 314/320 (98.1%) non-null\n",
      "   info_link: 320/320 (100.0%) non-null\n",
      "   collected_date: 320/320 (100.0%) non-null\n",
      "\n",
      "üìñ Sample Books:\n",
      "   Industrial Chocolate Manufacture and Use by Steve T. Beckett (Technology & Engineering) - 4.0/5 (1.0 ratings)\n",
      "   How We Became Posthuman by N. Katherine Hayles (Science) - 4.0/5 (7.0 ratings)\n",
      "   Darwin Among The Machines by George Dyson (Computers) - nan/5 (nan ratings)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=214'>215</a>\u001b[0m df \u001b[39m=\u001b[39m load_existing_data()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=216'>217</a>\u001b[0m \u001b[39mif\u001b[39;00m df \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=217'>218</a>\u001b[0m     \u001b[39m# Analyze existing data\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=218'>219</a>\u001b[0m     analyze_existing_data(df)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=220'>221</a>\u001b[0m     \u001b[39m# Clean and validate\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=221'>222</a>\u001b[0m     df_clean \u001b[39m=\u001b[39m clean_and_validate_data(df)\n",
      "\u001b[1;32m/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m sample\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     title \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUnknown\u001b[39m\u001b[39m'\u001b[39m)[:\u001b[39m50\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     authors \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mauthors\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mUnknown\u001b[39;49m\u001b[39m'\u001b[39;49m)[:\u001b[39m30\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     genre \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mgenre_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUnknown\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prashant/Desktop/me204-2025-project-prsnt95/notebooks/NB01-data-collection.ipynb#W2sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     rating \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39maverage_rating\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mN/A\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create data directories if they don't exist\n",
    "\n",
    "print(\"üìö Starting book data collection for ME204 Final Project\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def load_existing_data():\n",
    "    \"\"\"\n",
    "    Load existing book data from CSV file\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with book data or None if file doesn't exist\n",
    "    \"\"\"\n",
    "    csv_path = '../data/raw/books_raw_data.csv'\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"üìÅ Found existing data file: {csv_path}\")\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(f\"‚úÖ Successfully loaded {len(df)} books from existing file\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading existing file: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"üìÅ No existing data file found at: {csv_path}\")\n",
    "        return None\n",
    "\n",
    "def analyze_existing_data(df):\n",
    "    \"\"\"\n",
    "    Analyze the structure and content of existing data\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with book data\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìä Data Analysis:\")\n",
    "    print(f\"   Total books: {len(df)}\")\n",
    "    print(f\"   Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Check for genre distribution\n",
    "    if 'genre_name' in df.columns:\n",
    "        print(f\"\\nüìö Books by Genre:\")\n",
    "        genre_counts = df['genre_name'].value_counts()\n",
    "        for genre, count in genre_counts.items():\n",
    "            print(f\"   {genre}: {count} books\")\n",
    "    \n",
    "    # Check data quality\n",
    "    print(f\"\\nüîç Data Quality Check:\")\n",
    "    for col in df.columns:\n",
    "        non_null_count = df[col].notna().sum()\n",
    "        percentage = (non_null_count / len(df)) * 100\n",
    "        print(f\"   {col}: {non_null_count}/{len(df)} ({percentage:.1f}%) non-null\")\n",
    "    \n",
    "    # Show sample of data\n",
    "    print(f\"\\nüìñ Sample Books:\")\n",
    "    sample_cols = ['title', 'authors', 'genre_name', 'average_rating', 'ratings_count']\n",
    "    available_cols = [col for col in sample_cols if col in df.columns]\n",
    "    \n",
    "    if available_cols:\n",
    "        sample = df[available_cols].head(10)\n",
    "        for idx, row in sample.iterrows():\n",
    "            title = row.get('title', 'Unknown')[:50]\n",
    "            authors = row.get('authors', 'Unknown')[:30]\n",
    "            genre = row.get('genre_name', 'Unknown')\n",
    "            rating = row.get('average_rating', 'N/A')\n",
    "            count = row.get('ratings_count', 'N/A')\n",
    "            print(f\"   {title} by {authors} ({genre}) - {rating}/5 ({count} ratings)\")\n",
    "\n",
    "def select_top_books_by_genre(df, books_per_genre=50):\n",
    "    \"\"\"\n",
    "    Select top books from each genre based on ratings_count\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with all book data\n",
    "        books_per_genre: Number of books to select per genre\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with selected top books\n",
    "    \"\"\"\n",
    "    if 'genre_name' not in df.columns:\n",
    "        print(\"‚ùå No genre_name column found. Cannot filter by genre.\")\n",
    "        return df\n",
    "    \n",
    "    if 'ratings_count' not in df.columns:\n",
    "        print(\"‚ùå No ratings_count column found. Using original order.\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\nüèÜ Selecting top {books_per_genre} books per genre...\")\n",
    "    \n",
    "    # Convert ratings_count to numeric, handling any non-numeric values\n",
    "    df['ratings_count'] = pd.to_numeric(df['ratings_count'], errors='coerce').fillna(0)\n",
    "    \n",
    "    selected_books = []\n",
    "    \n",
    "    for genre in df['genre_name'].unique():\n",
    "        genre_books = df[df['genre_name'] == genre].copy()\n",
    "        \n",
    "        # Sort by ratings_count (descending) to get most popular books\n",
    "        genre_books = genre_books.sort_values('ratings_count', ascending=False)\n",
    "        \n",
    "        # Take top N books for this genre\n",
    "        top_books = genre_books.head(books_per_genre)\n",
    "        selected_books.append(top_books)\n",
    "        \n",
    "        print(f\"   {genre}: Selected {len(top_books)} books (max ratings: {top_books['ratings_count'].max():.0f})\")\n",
    "    \n",
    "    result_df = pd.concat(selected_books, ignore_index=True)\n",
    "    print(f\"\\n‚úÖ Total selected books: {len(result_df)}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_genre_mapping(df):\n",
    "    \"\"\"\n",
    "    Create a clean genre mapping table\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with book data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with genre mapping\n",
    "    \"\"\"\n",
    "    if 'genre_name' not in df.columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Create genre mapping\n",
    "    genres = df['genre_name'].unique()\n",
    "    genre_mapping = pd.DataFrame({\n",
    "        'genre_id': range(1, len(genres) + 1),\n",
    "        'genre_name': genres,\n",
    "        'description': [f'Books in the {genre} category' for genre in genres]\n",
    "    })\n",
    "    \n",
    "    return genre_mapping\n",
    "\n",
    "def clean_and_validate_data(df):\n",
    "    \"\"\"\n",
    "    Clean and validate the book data\n",
    "    \n",
    "    Args:\n",
    "        df: Raw DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"\\nüßπ Cleaning data...\")\n",
    "    initial_count = len(df)\n",
    "    \n",
    "    # Remove rows with missing essential data\n",
    "    essential_cols = ['book_id', 'title']\n",
    "    available_essential = [col for col in essential_cols if col in df.columns]\n",
    "    \n",
    "    if available_essential:\n",
    "        df = df.dropna(subset=available_essential)\n",
    "        print(f\"   Removed {initial_count - len(df)} books with missing essential data\")\n",
    "    \n",
    "    # Clean text fields\n",
    "    text_cols = ['title', 'authors', 'description', 'publisher']\n",
    "    for col in text_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).replace('nan', '').replace('None', '')\n",
    "    \n",
    "    # Ensure numeric fields are properly typed\n",
    "    numeric_cols = ['average_rating', 'ratings_count', 'page_count', 'genre_id']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Add collection timestamp if not present\n",
    "    if 'collected_date' not in df.columns:\n",
    "        df['collected_date'] = datetime.now().isoformat()\n",
    "    \n",
    "    print(f\"   Final dataset: {len(df)} books\")\n",
    "    return df\n",
    "\n",
    "def save_processed_data(df, genre_mapping=None):\n",
    "    \"\"\"\n",
    "    Save the processed data to files\n",
    "    \n",
    "    Args:\n",
    "        df: Processed book DataFrame\n",
    "        genre_mapping: Genre mapping DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"\\nüíæ Saving processed data...\")\n",
    "    \n",
    "    # Save main book data\n",
    "    df.to_csv('../data/raw/books_processed.csv', index=False)\n",
    "    print(f\"   ‚úÖ Saved books data: ../data/raw/books_processed.csv\")\n",
    "    \n",
    "    # Save genre mapping if available\n",
    "    if genre_mapping is not None and len(genre_mapping) > 0:\n",
    "        genre_mapping.to_csv('../data/raw/genres.csv', index=False)\n",
    "        print(f\"   ‚úÖ Saved genre mapping: ../data/raw/genres.csv\")\n",
    "    \n",
    "    # Create metadata\n",
    "    metadata = {\n",
    "        'processing_date': datetime.now().isoformat(),\n",
    "        'total_books': len(df),\n",
    "        'genres': df['genre_name'].unique().tolist() if 'genre_name' in df.columns else [],\n",
    "        'books_by_genre': df['genre_name'].value_counts().to_dict() if 'genre_name' in df.columns else {},\n",
    "        'columns': list(df.columns)\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open('../data/raw/processing_metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    print(f\"   ‚úÖ Saved metadata: ../data/raw/processing_metadata.json\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Try to load existing data\n",
    "    df = load_existing_data()\n",
    "    \n",
    "    if df is not None:\n",
    "        # Analyze existing data\n",
    "        analyze_existing_data(df)\n",
    "        \n",
    "        # Clean and validate\n",
    "        df_clean = clean_and_validate_data(df)\n",
    "        \n",
    "        # Select top books by genre (25 per genre = 100 total)\n",
    "        df_selected = select_top_books_by_genre(df_clean, books_per_genre=25)\n",
    "        \n",
    "        # Create genre mapping\n",
    "        genre_mapping = create_genre_mapping(df_selected)\n",
    "        \n",
    "        # Save processed data\n",
    "        save_processed_data(df_selected, genre_mapping)\n",
    "        \n",
    "        # Final summary\n",
    "        print(f\"\\nüìà Final Summary:\")\n",
    "        print(f\"   Total books selected: {len(df_selected)}\")\n",
    "        if 'genre_name' in df_selected.columns:\n",
    "            print(f\"   Books by genre:\")\n",
    "            for genre, count in df_selected['genre_name'].value_counts().items():\n",
    "                print(f\"     {genre}: {count}\")\n",
    "        \n",
    "        if 'ratings_count' in df_selected.columns:\n",
    "            print(f\"   Rating statistics:\")\n",
    "            print(f\"     Average ratings count: {df_selected['ratings_count'].mean():.0f}\")\n",
    "            print(f\"     Median ratings count: {df_selected['ratings_count'].median():.0f}\")\n",
    "            print(f\"     Max ratings count: {df_selected['ratings_count'].max():.0f}\")\n",
    "        \n",
    "        print(f\"\\nüèÜ Top 5 Most Popular Books:\")\n",
    "        if 'ratings_count' in df_selected.columns:\n",
    "            top_5 = df_selected.nlargest(5, 'ratings_count')\n",
    "            for idx, row in top_5.iterrows():\n",
    "                title = row.get('title', 'Unknown')[:40]\n",
    "                authors = row.get('authors', 'Unknown')[:25]\n",
    "                genre = row.get('genre_name', 'Unknown')\n",
    "                ratings = row.get('ratings_count', 0)\n",
    "                avg_rating = row.get('average_rating', 'N/A')\n",
    "                print(f\"   {title} by {authors} ({genre}) - {ratings:.0f} ratings, {avg_rating}/5\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No existing data found. Please ensure you have book data in '../data/raw/books_raw_data.csv'\")\n",
    "        print(\"üìù The CSV should have these columns:\")\n",
    "        expected_columns = [\n",
    "            'book_id', 'title', 'authors', 'publication_date', 'page_count', \n",
    "            'genre_name', 'genre_id', 'categories', 'average_rating', 'ratings_count',\n",
    "            'description', 'language', 'publisher', 'isbn_13', 'isbn_10', \n",
    "            'thumbnail', 'info_link', 'collected_date'\n",
    "        ]\n",
    "        for col in expected_columns:\n",
    "            print(f\"   - {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìù Next Steps:\")\n",
    "print(\"1. Review the processed data in ../data/raw/books_processed.csv\")\n",
    "print(\"2. Check ../data/raw/genres.csv for genre mapping\")\n",
    "print(\"3. Move to NB02-data-processing.ipynb to create your database\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
